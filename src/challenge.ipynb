{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LATAM Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*: Correr el siguiente bloque, que sirve para todos los m√©todos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with ZipFile(\"../tweets/tweets.json.zip\", 'r') as zObject: \n",
    "        zObject.extractall('.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Fechas y Usuarios\n",
    "\n",
    "### 1. Optimizaci√≥n de tiempo de ejecuci√≥n\n",
    "\n",
    "Para optimizar el tiempo de ejecuci√≥n se decidi√≥ cargar todos los datos de fecha y username de una vez, para despu√©s analizar los datos de forma compacta. A continuaci√≥n se define la funci√≥n con comentarios explicativos, junto con overhead necesario para medir el tiempo de ejecuci√≥n.\n",
    "\n",
    "Este m√©todo es mas lento que el realizado para optimizar memoria. Sin embargo, si el archivo fuera de menor tama√±o y estuviera en un formato sin tanto nesting, se podr√≠a utilizar una librer√≠a como Pandas para optimizar el enfoque de tiempo haciendo uso de vectorizaci√≥n. Para mejorarlo en este caso habr√≠a que dividir el set de datos en trozos mas peque√±os y hacer uso de threading, pero escapa de mis capacidades actuales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TIEMPO DE EJECUCION: 5.1851818561553955 --\n",
      "RESULTADO: \n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_time import q1_time\n",
    "\n",
    "initial_time = time()\n",
    "result = q1_time(file_path=file_path)\n",
    "print(f\"-- TIEMPO DE EJECUCION: {time() - initial_time} --\")\n",
    "print(\"RESULTADO: \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Optimizaci√≥n de uso de memoria\n",
    "\n",
    "Para este enfoque, se decidi√≥ analizar el archivo l√≠nea a l√≠nea, lo cual usa considerablemente menos memoria que el otro enfoque, y que, en este caso, tambi√©n resulta ser mas r√°pido, posiblemente dado el gran tama√±o del archivo analizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TIEMPO DE EJECUCION: 3.128476858139038 --\n",
      "RESULTADO: \n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_memory import q1_memory\n",
    "\n",
    "initial_time = time()\n",
    "result = q1_memory(file_path=file_path)\n",
    "print(f\"-- TIEMPO DE EJECUCION: {time() - initial_time} --\")\n",
    "print(\"RESULTADO: \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Contador de emojis\n",
    "\n",
    "### 1. Optimizaci√≥n de tiempo de ejecuci√≥n\n",
    "\n",
    "Para este problema se utiliz√≥ la librer√≠a [emoji](https://pypi.org/project/emoji/), la cual permite analizar strings para listar los emojis presentes. Con esta libreria, se decidi√≥ obtener el contenido de todos los tweets para formar un gran string, y analizar dicho string para obtener todos los emojis de una s√≥la vez. \n",
    "\n",
    "Como se ve mas adelante, este m√©todo tambi√©n result√≥ ser mas lento que con el enfoque l√≠nea a l√≠nea, y sospecho que tiene que ver el tama√±o del archivo `.json`. La estrategia propuesta para seguir optimizando el tiempo es la misma: compartimentalizar y usar threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TIEMPO DE EJECUCION: 12.93245005607605 --\n",
      "RESULTADO: \n",
      "[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972), ('üåæ', 2182), ('üáÆüá≥', 2086), ('ü§£', 1668), ('‚úä', 1651), ('‚ù§Ô∏è', 1382), ('üôèüèª', 1317), ('üíö', 1040)]\n"
     ]
    }
   ],
   "source": [
    "from q2_time import q2_time\n",
    "\n",
    "initial_time = time()\n",
    "result = q2_time(file_path=file_path)\n",
    "print(f\"-- TIEMPO DE EJECUCION: {time() - initial_time} --\")\n",
    "print(\"RESULTADO: \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Optimizaci√≥n de uso de memoria\n",
    "\n",
    "Para el c√≥digo en este enfoque se utiliz√≥ la misma l√≥gica que para el enfoque de optimizaci√≥n de tiempo, solo que analizando l√≠nea a l√≠nea en vez de armar un gran string con todos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TIEMPO DE EJECUCION: 12.900729179382324 --\n",
      "RESULTADO: \n",
      "[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972), ('üåæ', 2182), ('üáÆüá≥', 2086), ('ü§£', 1668), ('‚úä', 1651), ('‚ù§Ô∏è', 1382), ('üôèüèª', 1317), ('üíö', 1040)]\n"
     ]
    }
   ],
   "source": [
    "from q2_memory import q2_memory\n",
    "\n",
    "initial_time = time()\n",
    "result = q2_memory(file_path=file_path)\n",
    "print(f\"-- TIEMPO DE EJECUCION: {time() - initial_time} --\")\n",
    "print(\"RESULTADO: \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Contador de menciones\n",
    "\n",
    "### 1. Optimizaci√≥n de tiempo de ejecuci√≥n\n",
    "\n",
    "Este problema fue el mas sencillo de los tres. Lo √∫nico que se debe hacer es obtener eficientemente datos nesteados del archivo `.json`. La manera mas eficiente que encontr√© para realizar esto fue usar _list comprehension_ para iterar sobre los usuarios dentro de cada elemento `mentionedUsers`, y a su vez obtener el elemento `username` de cada `user`.\n",
    "\n",
    "Para mejorar la eficiencia de este m√©todo, ser√≠a mejor modificar la estructura de datos para no tener que ir tan abajo en la estructura del json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TIEMPO DE EJECUCION: 3.2523353099823 --\n",
      "RESULTADO: \n",
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "from q3_time import q3_time\n",
    "\n",
    "initial_time = time()\n",
    "result = q3_time(file_path=file_path)\n",
    "print(f\"-- TIEMPO DE EJECUCION: {time() - initial_time} --\")\n",
    "print(\"RESULTADO: \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Optimizaci√≥n de uso de memoria\n",
    "\n",
    "Para optimizar el uso de memoria, se utiliz√≥ el mismo m√©todo que para optimizar el tiempo de ejecuci√≥n, solo que l√≠nea a l√≠nea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TIEMPO DE EJECUCION: 3.1960067749023438 --\n",
      "RESULTADO: \n",
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "from q3_memory import q3_memory\n",
    "\n",
    "initial_time = time()\n",
    "result = q3_memory(file_path=file_path)\n",
    "print(f\"-- TIEMPO DE EJECUCION: {time() - initial_time} --\")\n",
    "print(\"RESULTADO: \")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
